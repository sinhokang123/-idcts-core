"""
IDCTS HAR Analysis Engine v2.0

HAR íŒŒì¼ì—ì„œ ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ì¦ê±°ë¥¼ ì¶”ì¶œí•˜ëŠ” ì—”ì§„
- ìŠ¤íŠ¸ë¦¬ë° ì„¸ê·¸ë¨¼íŠ¸ íŒ¨í„´ ê°ì§€ (jpg, ts, m3u8 ë“±)
- ì—°ì† íŒŒì¼ íŒ¨í„´ ê°ì§€ (segment_0001, chunk_001 ë“±)
- í”Œë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸ ê°ì§€ (video.js, player.js ë“±)
- CDN í—¤ë” ë¶„ì„
"""

import json
import re
from typing import Optional
from dataclasses import dataclass, field
from urllib.parse import urlparse
from collections import defaultdict


@dataclass
class StreamingEvidence:
    """ìŠ¤íŠ¸ë¦¬ë° ì¦ê±°"""
    playlist_url: Optional[str] = None
    segment_urls: list = field(default_factory=list)
    video_urls: list = field(default_factory=list)
    player_scripts: list = field(default_factory=list)
    player_domain: Optional[str] = None
    cdn_domain: Optional[str] = None
    total_segments: int = 0
    segment_pattern: Optional[str] = None
    segment_size_total: int = 0


@dataclass 
class HARAnalysisResult:
    """HAR ë¶„ì„ ê²°ê³¼"""
    total_requests: int = 0
    unique_domains: list = field(default_factory=list)
    streaming_evidence: Optional[StreamingEvidence] = None
    request_flow: list = field(default_factory=list)
    cdn_detection: dict = field(default_factory=dict)
    is_streaming_provider: bool = False
    confidence: str = "LOW"
    summary: str = ""
    detection_reasons: list = field(default_factory=list)


# ğŸ”¥ í™•ì¥ëœ ìŠ¤íŠ¸ë¦¬ë° í™•ì¥ì
STREAMING_EXTENSIONS = [
    ".m3u8", ".ts", ".mp4", ".webm", ".flv", ".m4s", ".m4v",
    ".mpd", ".dash", ".f4v", ".f4m", ".ism", ".isml"
]

# ğŸ”¥ ì„¸ê·¸ë¨¼íŠ¸ íŒ¨í„´ (íŒŒì¼ëª…ì—ì„œ ê°ì§€)
SEGMENT_PATTERNS = [
    r'segment[_-]?\d+',      # segment_0001, segment-001, segment001
    r'seg[_-]?\d+',          # seg_001, seg-001
    r'chunk[_-]?\d+',        # chunk_001, chunk-001
    r'part[_-]?\d+',         # part_001, part-001
    r'frag[_-]?\d+',         # frag_001 (fragment)
    r'ts[_-]?\d+',           # ts_001
    r'\d{4,}\.(?:jpg|jpeg|png|ts|mp4)',  # 0001.jpg, 00001.ts
    r'[a-z]+\d{3,}\.(?:jpg|jpeg|png|gif)',  # abc001.jpg
]

# ğŸ”¥ í”Œë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸ íŒ¨í„´
PLAYER_PATTERNS = [
    r'video.*\.js',          # video.js, video2.min.js
    r'player.*\.js',         # player.js, player.min.js
    r'hls.*\.js',            # hls.js, hls.min.js
    r'dash.*\.js',           # dash.js, dash.all.min.js
    r'jwplayer',             # jwplayer
    r'flowplayer',           # flowplayer
    r'plyr',                 # plyr
    r'videojs',              # videojs
    r'mediaelement',         # mediaelement
    r'clappr',               # clappr
]

# CDN í—¤ë”
CDN_HEADERS = {
    "cf-ray": "Cloudflare",
    "cf-cache-status": "Cloudflare",
    "x-cache": "CDN Cache",
    "x-amz-cf-id": "CloudFront",
    "x-amz-cf-pop": "CloudFront",
    "x-akamai-request-id": "Akamai",
    "x-served-by": "Fastly/Varnish",
    "x-cdn": "CDN",
    "via": "Proxy/CDN",
    "server": "Server",
    "x-hw": "Huawei CDN",
    "x-swift": "OpenStack Swift",
}

# ğŸ”¥ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë„ë©”ì¸ íŒ¨í„´
SUSPICIOUS_DOMAIN_PATTERNS = [
    r'cdn\d*\.',             # cdn1., cdn2.
    r'stream\d*\.',          # stream1., stream2.
    r'video\d*\.',           # video1., video2.
    r'media\d*\.',           # media1., media2.
    r'img\d*\.',             # img1., img2.
    r'static\d*\.',          # static1.
    r's\d+\.',               # s1., s2., s3.
    r'v\d+\.',               # v1., v2.
    r'edge\d*\.',            # edge1.
    r'node\d*\.',            # node1.
]


def extract_domain(url: str) -> str:
    """URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ"""
    try:
        return urlparse(url).netloc
    except:
        return ""


def extract_path(url: str) -> str:
    """URLì—ì„œ ê²½ë¡œ ì¶”ì¶œ"""
    try:
        return urlparse(url).path
    except:
        return ""


def is_streaming_url(url: str, mime_type: str = "") -> tuple:
    """ìŠ¤íŠ¸ë¦¬ë° URL íŒë³„ - í™•ì¥"""
    url_lower = url.lower()
    path = extract_path(url_lower)
    
    # 1. í™•ì¥ì ì²´í¬
    for ext in STREAMING_EXTENSIONS:
        if ext in url_lower:
            return True, ext.replace(".", ""), "extension"
    
    # 2. MIME íƒ€ì… ì²´í¬
    mime_lower = mime_type.lower()
    if any(m in mime_lower for m in ["mpegurl", "m3u8", "mp2t", "video", "octet-stream"]):
        return True, "mime", "mime_type"
    
    # 3. ğŸ”¥ ì„¸ê·¸ë¨¼íŠ¸ íŒ¨í„´ ì²´í¬
    for pattern in SEGMENT_PATTERNS:
        if re.search(pattern, path, re.IGNORECASE):
            return True, "segment", "segment_pattern"
    
    return False, "", ""


def is_player_script(url: str) -> bool:
    """í”Œë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸ ì—¬ë¶€"""
    url_lower = url.lower()
    for pattern in PLAYER_PATTERNS:
        if re.search(pattern, url_lower):
            return True
    return False


def is_suspicious_streaming_domain(domain: str) -> bool:
    """ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë° ë„ë©”ì¸"""
    domain_lower = domain.lower()
    for pattern in SUSPICIOUS_DOMAIN_PATTERNS:
        if re.search(pattern, domain_lower):
            return True
    return False


def analyze_sequential_files(urls: list) -> dict:
    """ì—°ì† íŒŒì¼ íŒ¨í„´ ë¶„ì„"""
    # íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ
    file_numbers = defaultdict(list)
    
    for url in urls:
        path = extract_path(url)
        filename = path.split('/')[-1]
        
        # ìˆ«ì ì¶”ì¶œ
        numbers = re.findall(r'\d+', filename)
        if numbers:
            # ê°€ì¥ ê¸´ ìˆ«ìë¥¼ ì‹œí€€ìŠ¤ ë²ˆí˜¸ë¡œ ê°„ì£¼
            seq_num = max(numbers, key=len)
            # íŒ¨í„´ ì¶”ì¶œ (ìˆ«ìë¥¼ {N}ìœ¼ë¡œ ëŒ€ì²´)
            pattern = re.sub(r'\d+', '{N}', filename)
            file_numbers[pattern].append(int(seq_num))
    
    # ì—°ì†ì„± ë¶„ì„
    sequential_patterns = {}
    for pattern, numbers in file_numbers.items():
        if len(numbers) >= 3:  # ìµœì†Œ 3ê°œ ì´ìƒ
            numbers_sorted = sorted(set(numbers))
            # ì—°ì† ì—¬ë¶€ ì²´í¬
            is_sequential = True
            gaps = []
            for i in range(1, len(numbers_sorted)):
                gap = numbers_sorted[i] - numbers_sorted[i-1]
                gaps.append(gap)
                if gap > 10:  # 10 ì´ìƒ ê±´ë„ˆë›°ë©´ ë¹„ì—°ì†
                    is_sequential = False
            
            if is_sequential or len(numbers) >= 10:
                sequential_patterns[pattern] = {
                    "count": len(numbers),
                    "min": min(numbers),
                    "max": max(numbers),
                    "is_sequential": is_sequential,
                    "avg_gap": sum(gaps) / len(gaps) if gaps else 0
                }
    
    return sequential_patterns


def analyze_har(har_data: str | dict) -> HARAnalysisResult:
    """HAR íŒŒì¼ ë¶„ì„ - v2.0"""
    
    result = HARAnalysisResult()
    streaming_evidence = StreamingEvidence()
    detection_reasons = []
    
    # HAR íŒŒì‹±
    try:
        if isinstance(har_data, str):
            har = json.loads(har_data)
        else:
            har = har_data
        entries = har.get("log", {}).get("entries", [])
    except Exception as e:
        result.summary = f"HAR íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
        return result
    
    result.total_requests = len(entries)
    
    domains_set = set()
    cdn_detections = {}
    all_urls = []
    segment_urls = []
    video_urls = []
    player_scripts = []
    streaming_domains = set()
    total_segment_size = 0
    
    # ê° ìš”ì²­ ë¶„ì„
    for entry in entries:
        request = entry.get("request", {})
        response = entry.get("response", {})
        
        url = request.get("url", "")
        domain = extract_domain(url)
        all_urls.append(url)
        
        if domain:
            domains_set.add(domain)
        
        # ì‘ë‹µ ì •ë³´
        content = response.get("content", {})
        mime_type = content.get("mimeType", "")
        content_size = content.get("size", 0) or 0
        
        # í—¤ë” íŒŒì‹±
        response_headers = {}
        for h in response.get("headers", []):
            response_headers[h.get("name", "").lower()] = h.get("value", "")
        
        request_headers = {}
        for h in request.get("headers", []):
            request_headers[h.get("name", "").lower()] = h.get("value", "")
        
        # CDN í—¤ë” ê°ì§€
        for header_key, cdn_name in CDN_HEADERS.items():
            if header_key in response_headers:
                if cdn_name not in cdn_detections:
                    cdn_detections[cdn_name] = []
                cdn_detections[cdn_name].append({
                    "domain": domain,
                    "header": header_key,
                    "value": response_headers[header_key][:100]
                })
        
        # ìŠ¤íŠ¸ë¦¬ë° URL ì²´í¬
        is_stream, stream_type, detection_method = is_streaming_url(url, mime_type)
        
        if is_stream:
            streaming_domains.add(domain)
            
            if stream_type == "m3u8":
                streaming_evidence.playlist_url = url
                detection_reasons.append(f"m3u8 í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë°œê²¬: {url[:80]}")
            elif stream_type == "segment":
                segment_urls.append(url)
                total_segment_size += content_size
            elif stream_type in ["ts", "mp4", "webm", "m4s"]:
                segment_urls.append(url)
                total_segment_size += content_size
            else:
                video_urls.append(url)
        
        # í”Œë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸ ì²´í¬
        if is_player_script(url):
            player_scripts.append(url)
            detection_reasons.append(f"ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸ ê°ì§€: {url.split('/')[-1]}")
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë„ë©”ì¸ ì²´í¬
        if is_suspicious_streaming_domain(domain):
            streaming_domains.add(domain)
    
    # ì—°ì† íŒŒì¼ íŒ¨í„´ ë¶„ì„
    sequential_analysis = analyze_sequential_files(all_urls)
    
    for pattern, info in sequential_analysis.items():
        if info["count"] >= 5:
            detection_reasons.append(
                f"ì—°ì† íŒŒì¼ íŒ¨í„´ ê°ì§€: {pattern} ({info['count']}ê°œ íŒŒì¼, #{info['min']}-#{info['max']})"
            )
            # ì—°ì† íŒŒì¼ë„ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ê°„ì£¼
            streaming_evidence.segment_pattern = pattern
    
    # ê²°ê³¼ ì •ë¦¬
    result.unique_domains = list(domains_set)
    result.cdn_detection = cdn_detections
    
    streaming_evidence.segment_urls = segment_urls
    streaming_evidence.video_urls = video_urls
    streaming_evidence.player_scripts = player_scripts
    streaming_evidence.total_segments = len(segment_urls)
    streaming_evidence.segment_size_total = total_segment_size
    
    # ğŸ”¥ ì—°ì† íŒ¨í„´ì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ ì¶”ê°€
    for pattern, info in sequential_analysis.items():
        if info["count"] >= 5:
            streaming_evidence.total_segments = max(
                streaming_evidence.total_segments, 
                info["count"]
            )
    
    # CDN ë„ë©”ì¸ ê²°ì •
    if streaming_domains:
        streaming_evidence.cdn_domain = list(streaming_domains)[0]
    elif segment_urls:
        segment_domains = [extract_domain(u) for u in segment_urls]
        if segment_domains:
            streaming_evidence.cdn_domain = max(set(segment_domains), key=segment_domains.count)
    
    result.streaming_evidence = streaming_evidence
    result.detection_reasons = detection_reasons
    
    # ğŸ”¥ ìŠ¤íŠ¸ë¦¬ë° ì œê³µì íŒì • (ê°•í™”)
    confidence_score = 0
    
    # íŒì • ê¸°ì¤€
    if streaming_evidence.playlist_url:
        confidence_score += 40
        detection_reasons.append("âœ“ m3u8 í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¡´ì¬")
    
    if streaming_evidence.total_segments >= 10:
        confidence_score += 35
        detection_reasons.append(f"âœ“ ìŠ¤íŠ¸ë¦¬ë° ì„¸ê·¸ë¨¼íŠ¸ {streaming_evidence.total_segments}ê°œ ë°œê²¬")
    elif streaming_evidence.total_segments >= 3:
        confidence_score += 20
        detection_reasons.append(f"âœ“ ìŠ¤íŠ¸ë¦¬ë° ì„¸ê·¸ë¨¼íŠ¸ {streaming_evidence.total_segments}ê°œ ë°œê²¬")
    
    if player_scripts:
        confidence_score += 15
        detection_reasons.append(f"âœ“ ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ {len(player_scripts)}ê°œ ê°ì§€")
    
    if sequential_analysis:
        for pattern, info in sequential_analysis.items():
            if info["count"] >= 10:
                confidence_score += 30
                break
            elif info["count"] >= 5:
                confidence_score += 15
                break
    
    if streaming_domains:
        confidence_score += 10
        detection_reasons.append(f"âœ“ ìŠ¤íŠ¸ë¦¬ë° ì˜ì‹¬ ë„ë©”ì¸: {', '.join(list(streaming_domains)[:3])}")
    
    if total_segment_size > 1024 * 1024:  # 1MB ì´ìƒ
        confidence_score += 10
        size_mb = total_segment_size / (1024 * 1024)
        detection_reasons.append(f"âœ“ ì´ ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°: {size_mb:.1f}MB")
    
    # ì‹ ë¢°ë„ ê²°ì •
    if confidence_score >= 60:
        result.confidence = "HIGH"
        result.is_streaming_provider = True
    elif confidence_score >= 30:
        result.confidence = "MEDIUM"
        result.is_streaming_provider = True
    elif confidence_score >= 15:
        result.confidence = "LOW"
        result.is_streaming_provider = True
    else:
        result.confidence = "NONE"
        result.is_streaming_provider = False
    
    # ìš”ì•½ ìƒì„±
    summary_lines = []
    summary_lines.append(f"ì´ {result.total_requests}ê°œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„")
    summary_lines.append(f"ê´€ë ¨ ë„ë©”ì¸ {len(result.unique_domains)}ê°œ ë°œê²¬")
    
    if streaming_evidence.total_segments > 0:
        summary_lines.append(f"ìŠ¤íŠ¸ë¦¬ë° ì„¸ê·¸ë¨¼íŠ¸ {streaming_evidence.total_segments}ê°œ ë°œê²¬")
    
    if streaming_evidence.playlist_url:
        summary_lines.append(f"ìŠ¤íŠ¸ë¦¬ë° í”Œë ˆì´ë¦¬ìŠ¤íŠ¸(m3u8) ë°œê²¬")
    
    if player_scripts:
        summary_lines.append(f"ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸ {len(player_scripts)}ê°œ ê°ì§€")
    
    if sequential_analysis:
        for pattern, info in sequential_analysis.items():
            if info["count"] >= 5:
                summary_lines.append(f"ì—°ì† íŒŒì¼ íŒ¨í„´: {pattern} ({info['count']}ê°œ)")
                break
    
    if streaming_evidence.cdn_domain:
        summary_lines.append(f"ì½˜í…ì¸  CDN: {streaming_evidence.cdn_domain}")
    
    if result.is_streaming_provider:
        summary_lines.append("")
        summary_lines.append("âš ï¸ íŒì •: ë³¸ ì‚¬ì´íŠ¸ëŠ” CDNì„ í†µí•´ ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë°ì„ ì œê³µí•˜ëŠ” ê²ƒìœ¼ë¡œ í™•ì¸ë¨")
        summary_lines.append(f"ì‹ ë¢°ë„: {result.confidence} (ì ìˆ˜: {confidence_score})")
    
    result.summary = "\n".join(summary_lines)
    
    return result


def generate_har_evidence_text(result: HARAnalysisResult) -> str:
    """HAR ë¶„ì„ ë²•ì  ì¦ê±° í…ìŠ¤íŠ¸ ìƒì„±"""
    
    lines = []
    lines.append("=" * 70)
    lines.append("HAR ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ê¸°ë°˜ ë²•ì  ì¦ê±°")
    lines.append("=" * 70)
    lines.append("")
    
    if not result.is_streaming_provider:
        lines.append("ë¶„ì„ ê²°ê³¼: ì§ì ‘ì ì¸ ìŠ¤íŠ¸ë¦¬ë° ì œê³µ ì¦ê±°ê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤.")
        lines.append("")
        lines.append(result.summary)
        lines.append("")
        lines.append("=" * 70)
        return "\n".join(lines)
    
    lines.append("ã€ë¶„ì„ ìš”ì•½ã€‘")
    lines.append(result.summary)
    lines.append("")
    
    lines.append("ã€ì¦ê±° ìƒì„¸ã€‘")
    for i, reason in enumerate(result.detection_reasons, 1):
        lines.append(f"  {i}. {reason}")
    lines.append("")
    
    if result.streaming_evidence:
        se = result.streaming_evidence
        lines.append("ã€ìŠ¤íŠ¸ë¦¬ë° ì¸í”„ë¼ ì •ë³´ã€‘")
        if se.playlist_url:
            lines.append(f"  - í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ URL: {se.playlist_url[:100]}")
        if se.cdn_domain:
            lines.append(f"  - CDN ë„ë©”ì¸: {se.cdn_domain}")
        lines.append(f"  - ì´ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {se.total_segments}ê°œ")
        if se.segment_size_total > 0:
            size_mb = se.segment_size_total / (1024 * 1024)
            lines.append(f"  - ì´ ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°: {size_mb:.2f}MB")
        if se.segment_pattern:
            lines.append(f"  - ì„¸ê·¸ë¨¼íŠ¸ íŒ¨í„´: {se.segment_pattern}")
        if se.player_scripts:
            lines.append(f"  - í”Œë ˆì´ì–´ ìŠ¤í¬ë¦½íŠ¸: {len(se.player_scripts)}ê°œ")
        lines.append("")
    
    lines.append("ã€ë²•ì  íŒë‹¨ ê·¼ê±°ã€‘")
    if result.confidence == "HIGH":
        lines.append("  ë³¸ ì‚¬ì´íŠ¸ëŠ” ë¶ˆë²• ì½˜í…ì¸ ì˜ 'ì§ì ‘ ì œê³µì'ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")
        lines.append("  - ìŠ¤íŠ¸ë¦¬ë° ì¸í”„ë¼ë¥¼ ì§ì ‘ ìš´ì˜í•˜ê³  ìˆìŒ")
        lines.append("  - ì½˜í…ì¸  ì „ì†¡ ì±…ì„ì´ ëª…í™•í•¨")
        lines.append("  - ì €ì‘ê¶Œë²• ìœ„ë°˜ ë° ì •ë³´í†µì‹ ë§ë²• ìœ„ë°˜ ì†Œì§€")
    elif result.confidence == "MEDIUM":
        lines.append("  ë³¸ ì‚¬ì´íŠ¸ëŠ” ë¶ˆë²• ì½˜í…ì¸ ì˜ 'ì œê³µì'ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤.")
        lines.append("  - ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ ì¦ê±°ê°€ ë‹¤ìˆ˜ ë°œê²¬ë¨")
        lines.append("  - ì¶”ê°€ ì¡°ì‚¬ë¥¼ í†µí•œ í™•ì¸ ê¶Œì¥")
    else:
        lines.append("  ìŠ¤íŠ¸ë¦¬ë° ì œê³µ ì¦ê±°ê°€ ì¼ë¶€ ë°œê²¬ë˜ì—ˆìœ¼ë‚˜ ì¶”ê°€ í™•ì¸ í•„ìš”")
    
    lines.append("")
    lines.append("=" * 70)
    
    return "\n".join(lines)
